#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
çº¯ Python å®ç°çš„æŠ–éŸ³è§†é¢‘æå–å™¨
ä¸ä¾èµ– douyinVd æœåŠ¡ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æç½‘é¡µ
"""

import re
import os
import json
import subprocess
from datetime import datetime
from typing import Optional, List, Dict, Any
import requests
import sys

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

try:
    from thumbnail_extractor import extract_thumbnail
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œå®šä¹‰ä¸€ä¸ªç©ºå‡½æ•°
    def extract_thumbnail(*args, **kwargs):
        return None


class DouyinVideoInfo:
    """æŠ–éŸ³è§†é¢‘ä¿¡æ¯"""

    def __init__(self):
        self.aweme_id: Optional[str] = None
        self.comment_count: Optional[int] = None
        self.digg_count: Optional[int] = None
        self.share_count: Optional[int] = None
        self.collect_count: Optional[int] = None
        self.nickname: Optional[str] = None
        self.signature: Optional[str] = None
        self.desc: Optional[str] = None
        self.create_time: Optional[str] = None
        self.video_url: Optional[str] = None
        self.type: Optional[str] = None
        self.image_url_list: Optional[List[str]] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "aweme_id": self.aweme_id,
            "comment_count": self.comment_count,
            "digg_count": self.digg_count,
            "share_count": self.share_count,
            "collect_count": self.collect_count,
            "nickname": self.nickname,
            "signature": self.signature,
            "desc": self.desc,
            "create_time": self.create_time,
            "video_url": self.video_url,
            "type": self.type,
            "image_url_list": self.image_url_list,
        }


class PurePythonExtractor:
    """çº¯ Python æŠ–éŸ³è§†é¢‘æå–å™¨"""

    # æ­£åˆ™è¡¨è¾¾å¼
    VIDEO_PATTERN = re.compile(r'"video":{"play_addr":{"uri":"([a-z0-9]+)"')
    VIDEO_URL_TEMPLATE = "https://www.iesdouyin.com/aweme/v1/play/?video_id=%s&ratio=1080p&line=0"

    STATS_REGEX = re.compile(r'"statistics"\s*:\s*\{([\s\S]*?)\},')
    NICKNAME_SIGNATURE_REGEX = re.compile(r'"nickname":\s*"([^"]+)",\s*"signature":\s*"([^"]+)"')
    CREATE_TIME_REGEX = re.compile(r'"create_time":\s*(\d+)')
    DESC_REGEX = re.compile(r'"desc":\s*"([^"]+)"')

    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 (Linux; Android 11; SAMSUNG SM-G973U) AppleWebKit/537.36 (KHTML, like Gecko) SamsungBrowser/14.2 Chrome/87.0.4280.141 Mobile Safari/537.36"
        })

    def _extract_thumbnail(self, video_path: str) -> Optional[str]:
        """
        ä»è§†é¢‘ä¸­æå–ç¼©ç•¥å›¾
        :param video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        :return: ç¼©ç•¥å›¾è·¯å¾„ï¼Œå¤±è´¥è¿”å› None
        """
        try:
            # ç”Ÿæˆç¼©ç•¥å›¾è·¯å¾„
            video_dir = os.path.dirname(video_path)
            video_name = os.path.splitext(os.path.basename(video_path))[0]
            thumbnail_path = os.path.join(video_dir, f"{video_name}_thumb.jpg")

            # ä½¿ç”¨ extract_thumbnail å‡½æ•°
            result = extract_thumbnail(video_path, thumbnail_path, "00:00:01")
            return result

        except Exception as e:
            print(f"âš ï¸ æå–ç¼©ç•¥å›¾å¤±è´¥: {e}")
            return None

    def format_date(self, timestamp: int) -> str:
        """æ ¼å¼åŒ–æ—¶é—´æˆ³"""
        date = datetime.fromtimestamp(timestamp)
        return date.strftime("%Y-%m-%d %H:%M:%S")

    def parse_img_list(self, body: str) -> List[str]:
        """è§£æå›¾ç‰‡åˆ—è¡¨"""
        content = body.replace(r"\u002F", "/").replace("/", "/")

        img_regex = re.compile(
            r'{"uri":"[^\s"]+","url_list":\["(https://p\d{1,2}-sign\.douyinpic\.com/[^"]+)"'
        )
        url_ret_regex = re.compile(r'"uri":"([^\s"]+)","url_list":')

        first_urls = img_regex.findall(content)
        url_list = url_ret_regex.findall(content)
        url_set = set(url_list)

        r_list = []
        for url_set_key in url_set:
            t = next((item for item in first_urls if url_set_key in item), None)
            if t:
                r_list.append(t)

        # è¿‡æ»¤æ‰åŒ…å« /obj/ çš„ URL
        filtered_r_list = [url for url in r_list if "/obj/" not in url]

        print(f"ğŸ“· æ‰¾åˆ° {len(filtered_r_list)} å¼ å›¾ç‰‡")
        return filtered_r_list

    def get_video_info(self, url: str) -> Optional[DouyinVideoInfo]:
        """
        è·å–è§†é¢‘ä¿¡æ¯
        :param url: æŠ–éŸ³è§†é¢‘é“¾æ¥
        :return: è§†é¢‘ä¿¡æ¯å¯¹è±¡
        """
        try:
            print(f"ğŸ” æ­£åœ¨è§£æ: {url}")

            # è¯·æ±‚é¡µé¢
            resp = self.session.get(url, timeout=10)
            resp.raise_for_status()
            body = resp.text

            # åˆ¤æ–­ç±»å‹ï¼ˆè§†é¢‘æˆ–å›¾ç‰‡ï¼‰
            video_type = "video"
            img_list: List[str] = []
            video_url = ""

            match = self.VIDEO_PATTERN.search(body)
            if not match:
                video_type = "img"
                print("ğŸ“¸ æ£€æµ‹åˆ°å›¾ç‰‡ç±»å‹")
            else:
                video_url = self.VIDEO_URL_TEMPLATE % match.group(1)
                print(f"ğŸ¬ æ£€æµ‹åˆ°è§†é¢‘ç±»å‹")
                print(f"ğŸ“º è§†é¢‘é“¾æ¥: {video_url}")

            if video_type == "img":
                img_list = self.parse_img_list(body)

            # è§£æå…¶ä»–ä¿¡æ¯
            au_match = self.NICKNAME_SIGNATURE_REGEX.search(body)
            ct_match = self.CREATE_TIME_REGEX.search(body)
            desc_match = self.DESC_REGEX.search(body)
            stats_match = self.STATS_REGEX.search(body)

            if not stats_match:
                print("âš ï¸ æœªæ‰¾åˆ°ç»Ÿè®¡ä¿¡æ¯")
                return None

            inner_content = stats_match.group(0)

            # æå–ç»Ÿè®¡æ•°æ®
            aweme_id_match = re.search(r'"aweme_id"\s*:\s*"([^"]+)"', inner_content)
            comment_count_match = re.search(r'"comment_count"\s*:\s*(\d+)', inner_content)
            digg_count_match = re.search(r'"digg_count"\s*:\s*(\d+)', inner_content)
            share_count_match = re.search(r'"share_count"\s*:\s*(\d+)', inner_content)
            collect_count_match = re.search(r'"collect_count"\s*:\s*(\d+)', inner_content)

            # æ„å»ºè§†é¢‘ä¿¡æ¯å¯¹è±¡
            douyin_video_info = DouyinVideoInfo()
            douyin_video_info.aweme_id = aweme_id_match.group(1) if aweme_id_match else None
            douyin_video_info.comment_count = int(comment_count_match.group(1)) if comment_count_match else 0
            douyin_video_info.digg_count = int(digg_count_match.group(1)) if digg_count_match else 0
            douyin_video_info.share_count = int(share_count_match.group(1)) if share_count_match else 0
            douyin_video_info.collect_count = int(collect_count_match.group(1)) if collect_count_match else 0
            douyin_video_info.video_url = video_url
            douyin_video_info.type = video_type
            douyin_video_info.image_url_list = img_list

            if au_match:
                douyin_video_info.nickname = au_match.group(1)
                douyin_video_info.signature = au_match.group(2)

            if ct_match:
                timestamp = int(ct_match.group(1))
                douyin_video_info.create_time = self.format_date(timestamp)

            if desc_match:
                douyin_video_info.desc = desc_match.group(1)

            print(f"âœ… è§£ææˆåŠŸ: {douyin_video_info.desc[:50] if douyin_video_info.desc else 'N/A'}")
            return douyin_video_info

        except Exception as e:
            print(f"âŒ è§£æå¤±è´¥: {e}")
            return None

    def download_video(self, url: str, output_dir: str, progress_callback=None) -> Dict[str, Any]:
        """
        ä¸‹è½½è§†é¢‘
        :param url: æŠ–éŸ³è§†é¢‘é“¾æ¥
        :param output_dir: è¾“å‡ºç›®å½•
        :param progress_callback: è¿›åº¦å›è°ƒå‡½æ•° callback(progress, message)
        :return: ä¸‹è½½ç»“æœ
        """
        try:
            # è·å–è§†é¢‘ä¿¡æ¯
            video_info = self.get_video_info(url)
            if not video_info:
                return {"success": False, "error": "æ— æ³•è·å–è§†é¢‘ä¿¡æ¯"}

            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(output_dir, exist_ok=True)

            downloaded_files = []

            # ä¸‹è½½è§†é¢‘
            if video_info.type == "video" and video_info.video_url:
                # ç”Ÿæˆæ–‡ä»¶å
                title = video_info.desc or f"douyin_{video_info.aweme_id}"
                # æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦
                title = re.sub(r'[\\/:*?"<>|]', '_', title)
                title = title[:100]  # é™åˆ¶é•¿åº¦

                video_filename = f"{title}_no_watermark.mp4"
                video_path = os.path.join(output_dir, video_filename)

                print(f"ğŸ“¥ å¼€å§‹ä¸‹è½½è§†é¢‘: {video_filename}")

                # ä¸‹è½½è§†é¢‘æ–‡ä»¶
                response = self.session.get(video_info.video_url, stream=True, timeout=30)
                response.raise_for_status()

                total_size = int(response.headers.get('content-length', 0))
                downloaded_size = 0
                last_progress = 0  # è®°å½•ä¸Šæ¬¡æŠ¥å‘Šçš„è¿›åº¦

                with open(video_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded_size += len(chunk)
                            if total_size > 0:
                                progress = (downloaded_size / total_size) * 100
                                current_progress = int(progress)

                                # åªåœ¨è¿›åº¦å˜åŒ–è‡³å°‘1%æ—¶æ›´æ–°ï¼ˆé¿å…è¿‡äºé¢‘ç¹ï¼‰
                                if current_progress != last_progress:
                                    print(f"\rğŸ“Š è¿›åº¦: {progress:.1f}%", end="", flush=True)

                                    # è°ƒç”¨è¿›åº¦å›è°ƒ
                                    if progress_callback:
                                        progress_callback(current_progress, f"ä¸‹è½½ä¸­ {progress:.1f}%")

                                    last_progress = current_progress

                print(f"\nâœ… è§†é¢‘ä¸‹è½½å®Œæˆ: {video_path}")

                # æå–è§†é¢‘ç¼©ç•¥å›¾
                thumbnail_path = self._extract_thumbnail(video_path)

                downloaded_files.append({
                    "type": "video",
                    "path": video_path,
                    "size": os.path.getsize(video_path),
                    "is_no_watermark": True,
                    "thumbnail": thumbnail_path  # æ·»åŠ ç¼©ç•¥å›¾è·¯å¾„
                })

            # ä¸‹è½½å›¾ç‰‡
            elif video_info.type == "img" and video_info.image_url_list:
                title = video_info.desc or f"douyin_{video_info.aweme_id}"
                title = re.sub(r'[\\/:*?"<>|]', '_', title)
                title = title[:100]

                for i, img_url in enumerate(video_info.image_url_list, 1):
                    img_filename = f"{title}_{i}.jpg"
                    img_path = os.path.join(output_dir, img_filename)

                    print(f"ğŸ“¥ ä¸‹è½½å›¾ç‰‡ {i}/{len(video_info.image_url_list)}: {img_filename}")

                    response = self.session.get(img_url, timeout=30)
                    response.raise_for_status()

                    with open(img_path, 'wb') as f:
                        f.write(response.content)

                    downloaded_files.append({
                        "type": "image",
                        "path": img_path,
                        "size": os.path.getsize(img_path)
                    })

                print(f"âœ… æ‰€æœ‰å›¾ç‰‡ä¸‹è½½å®Œæˆ")

            # ä¿å­˜å…ƒæ•°æ®ï¼ˆå¯é€‰ï¼Œé€šè¿‡å‚æ•°æ§åˆ¶ï¼‰
            # æ³¨é‡Šæ‰ï¼Œç”¨æˆ·ä¸éœ€è¦ JSON æ–‡ä»¶
            # metadata_filename = f"{title}_metadata.json"
            # metadata_path = os.path.join(output_dir, metadata_filename)
            #
            # with open(metadata_path, 'w', encoding='utf-8') as f:
            #     json.dump(video_info.to_dict(), f, ensure_ascii=False, indent=2)
            #
            # downloaded_files.append({
            #     "type": "metadata",
            #     "path": metadata_path,
            #     "size": os.path.getsize(metadata_path)
            # })

            return {
                "success": True,
                "video_info": video_info.to_dict(),
                "downloaded_files": downloaded_files
            }

        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {"success": False, "error": str(e)}


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    extractor = PurePythonExtractor()

    # æµ‹è¯• URL
    test_url = "https://v.douyin.com/vmyiIsBev5Y/"

    print("=" * 60)
    print("æµ‹è¯•çº¯ Python æŠ–éŸ³è§†é¢‘æå–å™¨")
    print("=" * 60)

    # è·å–è§†é¢‘ä¿¡æ¯
    info = extractor.get_video_info(test_url)
    if info:
        print("\nè§†é¢‘ä¿¡æ¯:")
        print(json.dumps(info.to_dict(), ensure_ascii=False, indent=2))

        # ä¸‹è½½è§†é¢‘
        # result = extractor.download_video(test_url, "test_downloads")
        # print(f"\nä¸‹è½½ç»“æœ: {result}")
